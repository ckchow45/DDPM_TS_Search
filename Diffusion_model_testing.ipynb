{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Model implementation for energy landscape exploration\n",
    "\n",
    "Testing ground for diffusion model implementation using pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mdtraj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# define the U-net structure\n",
    "model = Unet(\n",
    "    dim = 32,                   \n",
    "    dim_mults = (1, 2, 2, 4 ),   \n",
    "    groups = 8 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GaussianDiffusion.__init__() missing 1 required keyword-only argument: 'image_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# define diffusion model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m diffusion \u001b[38;5;241m=\u001b[39m \u001b[43mGaussianDiffusion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# U-net model\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# number of diffusion steps\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred_x0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# L1 or L2\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: GaussianDiffusion.__init__() missing 1 required keyword-only argument: 'image_size'"
     ]
    }
   ],
   "source": [
    "# define diffusion model\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# define the U-net structure\n",
    "model = Unet(\n",
    "    dim = 32,                   \n",
    "    dim_mults = (1, 2, 2, 4 ),   \n",
    "    groups = 8 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set training parameters\n",
    "trainer = Trainer(\n",
    "    diffusion,                                   # diffusion model\n",
    "    folder = 'traj_AIB9',                        # folder of trajectories\n",
    "    train_batch_size = 128,                      # training batch size\n",
    "    train_lr = 1e-5,                             # learning rate\n",
    "    train_num_steps = 2000000,                   # total training steps\n",
    "    gradient_accumulate_every = 1,               # gradient accumulation steps\n",
    "    ema_decay = 0.995,                           # exponential moving average decay\n",
    "    op_number = op_num,\n",
    "    fp16 = False                                 # turn on mixed precision training with apex\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "model_id = 30     \n",
    "trainer.load(model_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Assisted Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Handling\n",
    "\n",
    "    Current: The code uses a preprocessed .npy trajectory dataset.\n",
    "\n",
    "    Modify: Parse .mdcrd files into usable trajectory tensors.\n",
    "\n",
    "        Convert to .npy or torch.Tensor sequences.\n",
    "\n",
    "        Normalize or align structures (e.g. RMSD alignment).\n",
    "\n",
    "        Split into tuples: (start_frame, end_frame, full_path_sequence).\n",
    "\n",
    "2. Input Preparation\n",
    "\n",
    "    You’ll now want to encode the start and end frames as conditional inputs.\n",
    "\n",
    "        Option A: Concatenate start + end frames to the noisy input.\n",
    "\n",
    "        Option B: Encode start + end through a separate encoder and use in cross-attention or FiLM layers in the U-Net.\n",
    "\n",
    "3. Modify the UNet + Diffusion Model\n",
    "\n",
    "    Input shape: Instead of only receiving noisy intermediate x_t, the model receives:\n",
    "\n",
    "    model(noisy_frame_t, timestep_t, start_frame, end_frame)\n",
    "\n",
    "    Diffusion target: Instead of denoising a full trajectory from pure noise, the model learns to interpolate the path that connects the two known endpoints.\n",
    "\n",
    "    Loss: Compare predicted frame at time t to ground-truth frame in the trajectory using MSE/L2.\n",
    "\n",
    "4. Sampling (Inference)\n",
    "\n",
    "    After training:\n",
    "\n",
    "        Input start_frame and end_frame.\n",
    "\n",
    "        Initialize the intermediate frames as noise.\n",
    "\n",
    "        Use reverse diffusion steps to denoise iteratively — conditioning on both endpoints — to generate a discrete transition path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDCRD data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MDTraj python library to handle MDCRD files\n",
    "Corresponding topology file (prmtop) required\n",
    "\n",
    "Next we need to extract coordinates\n",
    " typically get an array of shape [num_frames, num_atoms, 3]. \n",
    "Let’s normalize and reshape:\n",
    "\n",
    "goal is to predict transition paths between two endpoint structures, you’ll want to create training samples like:\n",
    "(start_frame, end_frame, trajectory_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: path106.mdcrd\n",
      "Processing: path136.mdcrd\n",
      "Processing: path139.mdcrd\n",
      "Processing: path140.mdcrd\n",
      "Processing: path141.mdcrd\n",
      "Processing: path142.mdcrd\n",
      "Processing: path20.mdcrd\n",
      "Processing: path22.mdcrd\n",
      "Processing: path25.mdcrd\n",
      "Processing: path34.mdcrd\n",
      "Processing: path35.mdcrd\n",
      "Processing: path39.mdcrd\n",
      "Processing: path40.mdcrd\n",
      "Processing: path41.mdcrd\n",
      "Processing: path43.mdcrd\n",
      "Processing: path44.mdcrd\n",
      "Processing: path5.mdcrd\n",
      "Processing: path51.mdcrd\n",
      "Processing: path55.mdcrd\n",
      "Processing: path56.mdcrd\n",
      "Processing: path57.mdcrd\n",
      "Processing: path63.mdcrd\n",
      "Processing: path65.mdcrd\n",
      "Processing: path81.mdcrd\n",
      "Processing: path86.mdcrd\n",
      "Processing: path89.mdcrd\n",
      "Processing: path91.mdcrd\n"
     ]
    }
   ],
   "source": [
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "trajectory_folder = 'C:/Users/ckcho/OneDrive/Desktop/KCL Bioinformatics/Research_project/Paths/'       # folder containing all .mdcrd files\n",
    "topology_file = 'C:/Users/ckcho/OneDrive/Desktop/KCL Bioinformatics/Research_project/PK1/coords.prmtop'  # shared topology\n",
    "\n",
    "all_paths = []\n",
    "\n",
    "for file in os.listdir(trajectory_folder): #loop over all mdcrd files in the directory\n",
    "    if file.endswith(\".mdcrd\"): #check if the file ends with .mdcrd to make sure that only mdcrd files are selected\n",
    "        filepath = os.path.join(trajectory_folder, file) #get the full filepath of the path file\n",
    "        print(f\"Processing: {file}\")\n",
    "        \n",
    "        traj = md.load_mdcrd(filepath, top=topology_file) #load the trajectory into python\n",
    "\n",
    "        coords = traj.xyz #get the xyz (Cartersian) coordinates of the trajectories as a numpy array\n",
    "                          #all of the distances in the Trajectory are stored in nanometers. The time unit is picoseconds. Angles are stored in degrees (not radians).\n",
    "        \n",
    "        flattened = coords.reshape(coords.shape[0], -1) #need to flatten the frames into 1D for diffusion U-net model to accept\n",
    "        #goal is to predict paths between 2 endpoints so training samples should have a start and end point as well\n",
    "        #create tuples like (start_frame, end_frame, path) for training data\n",
    "        start = flattened[0]    # shape: (n_atoms * 3,), get the 1st frame of the path\n",
    "        end = flattened[-1]    # shape: (n_atoms * 3,), get the last frame of the path\n",
    "        path = flattened # the entire path\n",
    "        all_paths.append((start, end, path)) #append the tuple to a new list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "structure of output is as follows\n",
    "n number of path files is len(all_paths)\n",
    "    each element of all_paths holds 3 other elements\n",
    "    1st element is the coordinates for the 1st frame\n",
    "    2nd element is the coordinates for the last frame\n",
    "    3rd element are the coordinates for every other frame\n",
    "\n",
    "Each frame should hold 708 elements corresponding to each atom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2124"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_paths[0]) #length of each element should be number of frames in each path\n",
    "\n",
    "test = all_paths[0] #1st element is 299 frames for that path\n",
    "len(test[1]) #length is 708 atoms * 3 xyz coords = 2124 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a PyTorch dataset from the MDCRD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While training a model, we typically want to pass samples in batches and reshuffle the data at every epoch to reduce model overfitting\n",
    "# DataLoader is an iterable that abstracts this complexity in an easy API.\n",
    "from Landscape_DDPM import MolecularPathDataset, collate_paths\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = MolecularPathDataset(all_paths)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start shape: torch.Size([2124])\n",
      "End shape: torch.Size([2124])\n",
      "Path shape: torch.Size([299, 2124])\n"
     ]
    }
   ],
   "source": [
    "# how to access the dataset\n",
    "sample = dataset[0]\n",
    "print(\"Start shape:\", sample['start'].shape)\n",
    "print(\"End shape:\", sample['end'].shape)\n",
    "print(\"Path shape:\", sample['path'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 4/4 [00:15<00:00,  3.80s/it, loss=2.25e+3]\n",
      "Epoch 2/10: 100%|██████████| 4/4 [00:14<00:00,  3.54s/it, loss=2.22e+3]\n",
      "Epoch 3/10: 100%|██████████| 4/4 [00:15<00:00,  3.77s/it, loss=2.2e+3] \n",
      "Epoch 4/10: 100%|██████████| 4/4 [00:15<00:00,  3.80s/it, loss=2.18e+3]\n",
      "Epoch 5/10: 100%|██████████| 4/4 [00:15<00:00,  3.79s/it, loss=2.18e+3]\n",
      "Epoch 6/10: 100%|██████████| 4/4 [00:14<00:00,  3.70s/it, loss=2.17e+3]\n",
      "Epoch 7/10: 100%|██████████| 4/4 [00:15<00:00,  3.76s/it, loss=2.18e+3]\n",
      "Epoch 8/10: 100%|██████████| 4/4 [00:14<00:00,  3.54s/it, loss=2.17e+3]\n",
      "Epoch 9/10: 100%|██████████| 4/4 [00:12<00:00,  3.22s/it, loss=2.17e+3]\n",
      "Epoch 10/10: 100%|██████████| 4/4 [00:14<00:00,  3.60s/it, loss=2.16e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:/Users/ckcho/OneDrive/Desktop/KCL Bioinformatics/Research_project/Diffusion_model/Models\\molecular_path_diffusion.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Landscape_DDPM import GaussianDiffusion, Trainer, UNet\n",
    "\n",
    "# define the U-net structure\n",
    "n_atoms = 708\n",
    "F = n_atoms * 3\n",
    "\n",
    "model = UNet(\n",
    "    input_dim=F,           # atoms × 3 coordinates\n",
    "    base_dim=64,\n",
    "    dim_mults=(1, 2, 2, 4),\n",
    "    time_emb_dim=128,\n",
    "    out_dim=None         # same as in_dim by default\n",
    ")\n",
    "\n",
    "\n",
    "diffusion_model = GaussianDiffusion(\n",
    "    model,                        # U-net model\n",
    "    timesteps = 100,             # number of diffusion steps \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    diffusion=diffusion_model,           # Your GaussianDiffusion instance\n",
    "    dataloader=dataloader,               # From your earlier collate_paths function\n",
    "    ema_decay=0.995,\n",
    "    learning_rate=1e-5,\n",
    "    results_folder='C:/Users/ckcho/OneDrive/Desktop/KCL Bioinformatics/Research_project/Diffusion_model/Models',\n",
    "    save_name='molecular_path_diffusion.pt',\n",
    "    use_amp=True\n",
    ")\n",
    "trainer.train(num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Landscape_DDPM import GaussianDiffusion, Trainer, UNet\n",
    "# Load model state dict\n",
    "# define the U-net structure\n",
    "n_atoms = 708\n",
    "F = n_atoms * 3\n",
    "\n",
    "model = UNet(\n",
    "    input_dim=F,           # atoms × 3 coordinates\n",
    "    base_dim=64,\n",
    "    dim_mults=(1, 2, 2, 4),\n",
    "    time_emb_dim=128,\n",
    "    out_dim=None         # same as in_dim by default\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(\"C:/Users/ckcho/OneDrive/Desktop/KCL Bioinformatics/Research_project/Diffusion_model/Models/molecular_path_diffusion.pt\")\n",
    "model.load_state_dict(checkpoint['ema'])\n",
    "\n",
    "# Load diffusion wrapper\n",
    "diffusion = GaussianDiffusion(model, timesteps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start shape: torch.Size([1, 2124])\n",
      "end shape: torch.Size([1, 2124])\n"
     ]
    }
   ],
   "source": [
    "import mdtraj as md\n",
    "import torch\n",
    "# Configuration\n",
    "topology_file = 'C:/Users/ckcho/OneDrive/Desktop/KCL Bioinformatics/Research_project/PK1/coords.prmtop'\n",
    "\n",
    "traj = md.load_mdcrd('C:/Users/ckcho/OneDrive/Desktop/KCL Bioinformatics/Research_project/Paths/path5.mdcrd' , top=topology_file) #load the trajectory into python\n",
    "\n",
    "coords = traj.xyz #get the xyz (Cartersian) coordinates of the trajectories as a numpy array\n",
    "flattened = coords.reshape(coords.shape[0], -1) #need to flatten the frames into 1D for diffusion U-net model to accept\n",
    "\n",
    "#convert into tensors\n",
    "start = torch.tensor(flattened[0]).float()\n",
    "end = torch.tensor(flattened[-1]).float()\n",
    "#add extra 1 as model expects batch and I only want 1 sample\n",
    "start = start.unsqueeze(0)  # (1, F)\n",
    "end = end.unsqueeze(0)      # (1, F)\n",
    "print(\"start shape:\", start.shape)  # Should be (1, F)\n",
    "print(\"end shape:\", end.shape)      # Should be (1, F)\n",
    "\n",
    "#generate path\n",
    "generated_path = diffusion.sample(model, start, end, frames=50, device = 'cpu')  # (1, 50, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 708, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "generated_path = generated_path.squeeze(0)  # Shape: (50, F), remove the batch number\n",
    "generated_xyz = generated_path.reshape(-1, n_atoms, 3) # turn into format \n",
    "generated_coordinates = generated_xyz.numpy()\n",
    "generated_coordinates.shape # output multidimensional array (number of frames, number of atoms, XYZ coordinates for each atom)\n",
    "                            # so frame 1 will contain 708 entries of 3 coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_xyz(coordinates, filename, atom_names=None):\n",
    "    \"\"\"\n",
    "    Save a trajectory as an XYZ file.\n",
    "    \n",
    "    Parameters:\n",
    "    - coordinates: (T, N, 3) array of frames\n",
    "    - filename: output filename\n",
    "    - atom_names: list of atom names (optional, defaults to 'C')\n",
    "    \"\"\"\n",
    "    frames, atoms, _ = coordinates.shape\n",
    "    if atom_names is None:\n",
    "        atom_names = ['C'] * atoms  # Default to carbon\n",
    "\n",
    "    with open(filename, 'w') as file:\n",
    "        for f in range(frames): # loop over every frame\n",
    "            file.write(str(atoms) + \"\\n\") # number of atoms\n",
    "            file.write(f\"Frame {f+1}\\n\") # comment line just saying which frame the following information is, +1 to avoid 0 indexing\n",
    "            for i in range(atoms): # loop over every atom\n",
    "                x, y, z = coordinates[f, i] # extract coordinates from each frame and atom\n",
    "                file.write(f\"{atom_names[i]} {x:.5f} {y:.5f} {z:.5f}\\n\") # write each coordinate the .5f is python string formatting to only show 5 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mdtraj as md\n",
    "\n",
    "# Configuration\n",
    "topology = md.load_prmtop('C:/Users/ckcho/OneDrive/Desktop/KCL Bioinformatics/Research_project/PK1/coords.prmtop')\n",
    "traj = md.load_mdcrd('C:/Users/ckcho/OneDrive/Desktop/KCL Bioinformatics/Research_project/Paths/path5.mdcrd' , top=topology_file) #load the trajectory into python\n",
    "\n",
    "topology.atoms\n",
    "atom_elements = [atom.element.symbol for atom in topology.atoms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_xyz(generated_coordinates, 'generated_path.xyz', atom_elements)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
